
<!-- saved from url=(0025)http://yhlleo.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <title>Xiaoyan Lu</title>
  <meta content="Xiaoyan Lu, luxiaoyan95.github.io" name="keywords">
  <style media="screen" type="text/css">html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}
a {
  color: #1772d0;
  text-decoration:none;
}
a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}
a.paper {
  font-weight: bold;
  font-size: 12pt;
}
b.paper {
  font-weight: bold;
  font-size: 12pt;
}
* {
  margin: 0pt;
  padding: 0pt;
}
body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 900px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15px;
  background: #eee;
}
h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16pt;
  font-weight: 700;
}
h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 17px;
  font-weight: 700;
  padding-bottom: 0.5em;
}
strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  font-weight:bold;
}
ul { 
  list-style: circle;
}
img {
  border: none;
}
li {
  padding-bottom: 0.6em;
  margin-left: 1.4em;
}
alert {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight: bold;
  color: #FF0000;
}
em, i {
  font-style:italic;
}
div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}
div.spanner {
  clear: both;
}
div.paper {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}
div.paper div {
  padding-left: 230px;
}
img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 200px;
}
span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}
pre, code {
  font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
  margin: 1em 0;
  padding: 0;
}
div.paper pre {
  font-size: 0.9em;
}

.paper-title {
    color: #003399;
    font-weight: 500;
}
</style>

<link href="./index_files/css" rel="stylesheet" type="text/css"><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
<script async="" src="http://www.google-analytics.com/analytics.js"></script><script async="" src="http://www.google-analytics.com/analytics.js"></script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-45959174-3', 'yhlleo.github.io');
  ga('send', 'pageview');
</script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-66888300-1', 'auto');
  ga('send', 'pageview');
</script><script type="text/javascript" src="./index_files/jquery-1.12.4.min.js"></script></head>


<body>
<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 230px;">
<div style="margin: 0px auto; width: 100%;">
<img title="Xiaoyan Lu" style="float: left; padding-left: .01em; height: 230px;" src="./index_files/lxy.jpg">
<div style="padding-left: 12em; vertical-align: top; height: 120px;"><span style="line-height: 200%; font-size: 20pt;"><strong>Xiaoyan Lu</strong></span><br>
<br>
<span><strong>PhD student</strong></span><br>
<br>
<span><a href="http://www.lmars.whu.edu.cn/" target="_blank">State Key Laboratory of Information Engineering, Survey Mapping and Remote Sensing (LIESMARS)</a>,
<span><a href="https://www.whu.edu.cn/" target="_blank">Wuhan University, China</a><br />
<br>
<span><strong>Address</strong>: No. 2 Teaching Building 301-Room, Luoyu Road #129, Hongshan District, Wuhan, Hubei, China </span><br>
<span><strong>Email</strong>: luxiaoyan@whu.edu.cn</span> &nbsp &nbsp
[<a href="https://scholar.google.com/citations?hl=zh-CN&user=LmKDWMQAAAAJ" target="_blank">Google Scholar</a>]
[<a href="https://www.researchgate.net/profile/Xiaoyan-Lu-5" target="_blank">ResearchGate</a>]</span><br>


</span></div>
</div>
</div>
<!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->

<div style="clear: both;">
<div class="section">
<h2>About Me (<a href="http://yhlleo.github.io/index_files/cv.pdf">CV</a>)</h2>
<div class="paper">

I'm a second-year Ph.D. student in <a href="http://rsidea.whu.edu.cn/">Intelligent Data Extraction, Analysis and Applications of Remote Sensing (RSIDEA group)</a>. My research interest include <b>computer vision</b>, <b>ground object extraction from high resolution remote sensing images</b> and <b>intelligent interpretation and application of medical images</b>.
<br>
<br>
<ul>
  <li>2019.9-Now &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ph.D in <a href="http://www.lmars.whu.edu.cn/" target="_blank">LIESMARS</a>, <a href="https://www.whu.edu.cn/" target="_blank">Wuhan University</a>. Supervisor: Prof. <a href="http://rsidea.whu.edu.cn/" target="_blank">Yanfei Zhong</a> & <a href="http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/index.html" target="_blank">Liangpei Zhang</a></li>
  <Li>2017.9-2019.6 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; M.S. in <a href="http://www.lmars.whu.edu.cn/" target="_blank">LIESMARS</a>, <a href="https://www.whu.edu.cn/" target="_blank">Wuhan University</a>. Supervisor: Prof. <a href="http://rsidea.whu.edu.cn/" target="_blank">Yanfei Zhong</a> </li>
  <li>2013.9-2017.6 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; B.S. in <a href="http://gip.csu.edu.cn/" target="_blank">School of GeoSciences and Info-Physics</a>, <a href="https://www.csu.edu.cn/" target="_blank">Central South University</a>.</li>
</ul>
</div>
</div>
</div>

<div style="clear: both;">
<div class="section">
  <h2>News</h2>
  <div class="paper">
  <ul>
  <li> 4/2021: One paper is accepted by ISPRS P&RS. </li>
  <li> 3/2021: the <a href="https://www.ingentaconnect.com/content/asprs/pers/2020/00000086/00000003/art00006">PE&RS paper </a>  wins the first place in the 2021 John I. Davidson President’s Award.  </li>
  </ul>
  </div>
</div>
</div>


<div style="clear: both;">
<div class="section">
  <h2>Research Experience</h2>
  <div class="paper">
  <ul> 
    <li><b>Tencent AI Lab</b>, Shenzhen, China. 9/2020 -- ? <br> 
      Mentors: Dr. <a href="https://scholar.google.com/citations?user=xQZMbkUAAAAJ&hl=en">Linchao Bao</a> and Dr. <a href="https://scholar.google.com/citations?user=aSJcgQMAAAAJ&hl=en">Wei Bi</a>. <br>
      GANs, Image Domain Translation. </li> 
    <li><b>FBK and MHUG</b>, Trento, Italy. 12/2018 -- 06/2022 <br>
      Mentors: Prof. <a href="https://scholar.google.com/citations?hl=en&user=tNtjSewAAAAJ">Nicu Sebe</a> and Dr. <a href="https://scholar.google.com/citations?user=zN5RTZcAAAAJ&hl=en">Bruno Lepri</a>. <br>
      Deep learning, GANs, Cross-modal Representations, Image Domain Translation. </li>
    <li><b>Tencent AI Lab</b>, Shenzhen, China. 11/2017 -- 09/2018 <br>
      Mentors: Dr. <a href="https://scholar.google.com/citations?user=aSJcgQMAAAAJ&hl=en">Wei Bi</a> and Dr. <a href="https://scholar.google.com/citations?user=ukdqC6IAAAAJ&hl=en">Xiaojiang Liu</a>.<br> 
      Deep Learning, Neural Dialogue Generation. </li>
    <li>Computer Vision and Remote Sensing (<b>CVRS</b>) Lab, Wuhan, China. 03/2015 -- 06/2018<br> 
      Mentor: Prof. <a href="https://scholar.google.com/citations?hl=en&user=lV0Wxw0AAAAJ">Jian Yao</a>. <br> 
      Deep Learning, Remote Sensing. </li>
  </ul>
  </div>
</div>
</div>

<div style="clear: both;">
<div class="section">
  <h2>Publications</h2>

  <h3 id="confpapers">&#10022 <i>Journals</i> </h3>
  <div class="paper">
    <ul>
      <li>
        <img title="vanishing" style="float: right; padding-right: .01em; width: 290px;" src="./figures/license-detection.png">
        <span class="paper-title">Multi-Oriented and Scale-Invariant License Plate Detection Based on Convolutional Neural Networks</span>. <br>
        Jing Han, Jian Yao, Jiao Zhao, Jingmin Tu, and <b>Yahui Liu</b>. <br>
        <strong>Sensors</strong>, Volume: 19, Issue: 5, Page(s): 1175, 2019. (Impact factor: 3.031). <br>
        <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6427508/">[paper]</a>
      </li>
    </ul>
  </div>

  <div class="paper">
    <ul>
      <li>
        <img title="vanishing" style="float: right; padding-right: .01em; width: 300px;" src="./figures/deepcrack.png">
        <span class="paper-title">DeepCrack: A Deep Hierarchical Feature Learning Architecture for Crack Segmentation</span>.<br>
        <b>Yahui Liu</b>, Jian Yao, Rengping Xie, and Li Li. <br>
        <strong>Neurocomputing</strong>, Volume: 338, Page(s): 139-153, 2019. (Impact factor: 4.072). <br>
        <a href="http://yhlleo.github.io/papers/DeepCrack-Neurocomputing2019.pdf">[paper]</a><a href="https://github.com/yhlleo/DeepCrack">[code & dataset]</a>
      </li>
    </ul>
  </div>

  <div class="paper">
    <ul>
      <li>
        <img title="vanishing" style="float: right; padding-right: .01em; width: 300px;" src="./figures/roadnet.png">
        <span class="paper-title">RoadNet: Learning to Comprehensively Analyze Road Networks in Complex Urban Scenes From High-Resolution Remotely Sensed Images</span>. <br>
        <b>Yahui Liu</b>, Jian Yao, Xiaohu Lu, Menghan Xia, Xingbo Wang, and Yuan Liu. <br>
        IEEE Transactions on Geoscience and Remote Sensing(<strong>TGRS</strong>), Volume: 57, Issue: 4, Page(s): 2043-2056, 2019. (Impact factor: 5.63). <br>
        <a href="http://yhlleo.github.io/papers/RoadNet-TGRS2019.pdf">[paper]</a><a href="https://github.com/yhlleo/RoadNet">[code & dataset]</a>
      </li>
    </ul>
  </div>

  <div class="paper">
    <ul>
      <li>
        <span class="paper-title">Automatic Multi-image Stitching for Concrete Bridge Inspection by Combining Point and Line Features</span>. <br>
        Renping Xie, Jian Yao, Kang Liu, Xiaohu Lu, <b>Yahui Liu</b>, Menghan Xia, and Qifei Zeng. <br>
        <b>Automation in Construction</b>, Volume: 90, Page(s): 265-280, 2018. (Impact factor: 4.313).
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0926580518301237">[paper]</a>
      </li>
    </ul>
  </div>

  <div class="paper">
    <ul>
      <li>
        <span class="paper-title">Optimal Seamline Detection for Orthoimage Mosaicking by Combining Deep Convolutional Neural Network and Graph Cuts</span>. <br>
        Li Li, Jian Yao, <b>Yahui Liu</b>, Wei Yuan, Shuzhu Shi, and Shenggu Yuan. <br>
        <b>Remote Sensing</b>, Volume: 9, Page(s): 701, 2017. (Impact factor: 4.118).
        <a href="https://www.mdpi.com/2072-4292/9/7/701">[paper]</a>
      </li>
    </ul>
  </div>
</div>
</div>







  <h3 id="confpapers">&#10022 <i>Conferences</i></h3>  
  <div class="paper">
  <ul>
    <li>
      <span class="paper-title">Assessing Dialogue Systems with Distribution Distances</span>. <br>
      Jiannan Xiang*, <b>Yahui Liu</b>*, Deng Cai, Huayang Li, Defu Lian and Lemao Liu <br>
      (*denotes equal contribution) <br>
      <i>to appear in Findings of the Association for Computational Linguistics</i>(<b>Findings of ACL</b>), 2021. <br>
      <a href="https://arxiv.org/pdf/2105.02573.pdf">[arXiv]</a><a href="https://github.com/yhlleo/frechet-bert-distance">[code]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul>
    <li>
      <img title="semantic-guided" style="float: right; padding-right: .01em; width: 300px;" src="./figures/smooth-latent-space.png">
      <span class="paper-title">Smoothing the Disentangled Latent Style Space for Unsupervised Image-to-Image Translation</span>. <br>
      <b>Yahui Liu</b>, Enver Sangineto, Yajing Chen, Linchao Bao, Haoxian Zhang, Nicu Sebe, Bruno Lepri, Wei Wang,  Marco De Nadai <br>
      <i>to appear in IEEE/CVF Conference on Computer Vision and Pattern Recognition</i>(<b>CVPR</b>), 2021. <br>
      [arXiv][paper]<a href="https://github.com/yhlleo/SmoothingLatentSpace">[code]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul>
    <li>
      <img title="semantic-guided" style="float: right; padding-right: .01em; width: 300px;" src="./figures/semantic-guided.png">
      <span class="paper-title">Semantic-Guided Inpainting Network for Complex Urban Scenes Manipulation</span>. <br>
      Pierfrancesco Ardino, <b>Yahui Liu</b>, Elisa Ricci, Bruno Lepri, Marco De Nadai <br>
      <i>International Conference on Pattern Recognition</i>(<b>ICPR</b>), 2020. <br> 
      <a href="https://arxiv.org/abs/2010.09334">[arXiv]</a> <a href="https://github.com/PierfrancescoArdino/SGINet">[code]</a>
    </li>
  </ul>
  </div>
    
  <div class="paper">
  <ul>
    <li>
      <img title="dwcgan" style="float: right; padding-right: .01em; width: 300px;" src="./figures/discribe-what-to-change.png">
      <span class="paper-title">Describe What to Change: A Text-guided Unsupervised Image-to-Image Translation Approach</span>. <br>
      <b>Yahui Liu</b>, Marco De Nadai, Deng Cai, Huayang Li, Xavier Alameda-Pineda, Nicu Sebe, and Bruno Lepri. <br>
      <i>ACM International Conference on Multimedia</i>(<b>ACM MM</b>, Oral), 2020. <br>
      <a href="https://arxiv.org/abs/2008.04200">[arXiv]</a><a href="https://dl.acm.org/doi/abs/10.1145/3394171.3413505">[paper]</a><a href="https://github.com/yhlleo/DWC-GAN">[code]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul>
    <li>
      <img title="rg-unit" style="float: right; padding-right: .01em; width: 300px;" src="./figures/retrieval-guided.png">
      <span class="paper-title">Retrieval Guided Unsupervised Multi-domain Image-to-Image Translation</span>. <br>
      Raul Gomez*, <b>Yahui Liu</b>*, Marco De Nadai, Dimosthenis Karatzas, Nicu Sebe, and Bruno Lepri. <br>
      (*denotes equal contribution) <br>
      <i>ACM International Conference on Multimedia</i>(<b>ACM MM</b>, Poster), 2020.
      <a href="http://arxiv.org/abs/2008.04991">[arXiv]</a><a href="https://dl.acm.org/doi/10.1145/3394171.3413785">[paper]</a><a href="https://github.com/yhlleo/RG-UNIT">[code]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul>  
    <li>
      <img title="g2g" style="float: right; padding-right: .01em; width: 280px;" src="./figures/gesture-to-gesture.png">
      <span class="paper-title">Gesture-to-Gesture Translation in the Wild via Category-Independent Conditional Maps</span>. <br>
      <b>Yahui Liu</b>, Marco De Nadai, Gloria Zen, Nicu Sebe, and Bruno Lepri. <br>
      <i>ACM International Conference on Multimedia</i>(<b>ACM MM</b>, Poster), 2019. <br>
      <a href="https://arxiv.org/pdf/1907.05916.pdf">[arXiv]</a><a href="https://dl.acm.org/doi/10.1145/3343031.3351020">[paper]</a><a href="https://github.com/yhlleo/TriangleGAN">[code & dataset]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul>  
    <li>
      <span class="paper-title">Towards Less Generic Responses in Neural Conversation Models: A Statistical Re-weighting Method</span>. <br>
      <b>Yahui Liu</b>, Victoria Bi, Jun Gao, Xiaojiang Liu, Jian Yao, and Shuming Shi. <br>
      <i>Conference on Empirical Methods in Natural Language Processing</i>(<strong>EMNLP</strong>, Oral), 2018. <br>
      <a href="https://www.aclweb.org/anthology/D18-1297.pdf">[paper]</a><a href="https://github.com/yhlleo/Reweighting">[code & dataset]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul>  
    <li>
      <img title="vanishing" style="float: right; padding-right: .01em; width: 300px;" src="./figures/vanishing-lines.png">
      <span class="paper-title">2-Line Exhaustive Searching for Real-Time Vanishing Point Estimation in Manhattan World</span>. <br>
      Xiaohu Lu, Jian Yao, Xiaofeng Zhang, Haoang Li, <b>Yahui Liu</b>. <br>
      <i>IEEE Winter Conference on Applications of Computer Vision</i>(<strong>WACV</strong>), 2017. <br>
      <a href="http://yhlleo.github.io/papers/Vanishing_Point_Detection_WACV2017.pdf">[paper]</a><a href="https://github.com/xiaohulugo/VanishingPointDetection">[code]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul>  
  <li>
    <img title="vanishing" style="float: right; padding-right: .01em; width: 280px;" src="./figures/edge-chain.png">
    <span class="paper-title">Edge Chain Detection by Applying Helmholtz Principle on Gradient Magnitude Map</span>. <br>
    Xiaohu Lu, Jian Yao, Li Li, <b>Yahui Liu</b>, and Wei Zhang. <br>
    <i>IAPR International Conference on Pattern Recognition</i>(<strong>ICPR</strong>, Oral), 2016. <br>
    <a href="http://yhlleo.github.io/papers/Edge_Chain_Detection_ICPR2016.pdf">[paper]</a>
  </li>
  </ul>
  </div>

  




<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Professional Activities</h2>
<div class="paper">
  <h3>Journal Reviewer</h3>
    <ul>
    <li> IEEE Transactions on Industrial Informatics (<b>TII</b>) </li>
    <li> IEEE Geoscience and Remote Sensing Letters (<b>GRSL</b>) </li>
    <li> IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (<b>J-STARS</b>) </li>
    </ul>
  <h3>Conference reviewer/TPC member</h3>
  <ul>
    <li> The 29th ACM International Conference on Multimedia (<b>ACM MM 2021</b>) </li>
    <li> IEEE/CVF International Conference on Computer Vision (<b>ICCV 2021</b>) </li>
    <li> IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR 2021</b>) </li>
    <li> The 30th International Joint Conference on Artificial Intelligence (<b>IJCAI 2021</b>) </li>
    <li> The 28th ACM International Conference on Multimedia (<b>ACM MM 2020</b>) </li>
  </ul>
</div>
</div>
</div>

<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Awards</h2>
<div class="paper">
    <ul>
      <li>2021, First-place of the 2021 John I. Davidson President' s Award, ASPRS |(<a href="https://conferences.asprs.org/class/awardpers/" target="_blank"><font style="font-family:Microsoft YaHei">美国摄影测量与遥感学会 Davidson 主席奖第一名</font></a>)</li>

      <li>2020, Hongtu Chuangzhan Scholarship, Wuhan University | (<a href="https://info.whu.edu.cn/info/1447/17855.htm" target="_blank"><font style="font-family:Microsoft YaHei">武汉大学宏图创展奖学金一等奖</font></a>)</li>
      <li>2020, First Prize of Academic Scholarship, Wuhan University | <font style="font-family:Microsoft YaHei">武汉大学博士一等学业奖学金</font></li>
      <li>2020, Activist of Social Activities in Wuhan University | <font style="font-family:Microsoft YaHei">武汉大学社会活动积极分子</font></li>
      <li>2020, Outstanding Graduate Student, Wuhan University | <font style="font-family:Microsoft YaHei">武汉大学优秀研究生</font></li>
      <li>2019, Outstanding Graduate of Wuhan University | <font style="font-family:Microsoft YaHei">武汉大学优秀毕业生</font></li>
      <li>2018, First Prize of Academic Scholarship, Wuhan University | <font style="font-family:Microsoft YaHei">武汉大学硕士一等学业奖学金</font></li>
      <li>2018, Outstanding Student Leader of Wuhan University | <font style="font-family:Microsoft YaHei">武汉大学优秀学生干部</font></li>
      <li>2018, Outstanding Graduate Student, Wuhan University | <font style="font-family:Microsoft YaHei">武汉大学优秀研究生</font></li>
      <li>2018, Excellent Report Award of "The 8th National Doctoral Academic Forum on Geographic Information Science" | <font style="font-family:Microsoft YaHei">“第八届全国地理信息科学博士生学术论坛”优秀报告奖</font></li>
    </ul>
</div>
</div>
</div>


<div style="clear: both;">
<div class="section">
<h2 id="confpapers">My family</h2>
<div class="paper">
    <ul>
    <li> <a href="https://www.researchgate.net/profile/Yahui-Liu-7">ResearchGate</a> </li>
    </ul>
</div>
</div>
</div>


<div style="clear:both;">
<p align="right"><font size="5">Last Updated on 5 June, 2021</font></p>
</div>

<div class="jvectormap-tip"></div></body></html>
